<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Evgeniy Zabrodskiy" />

<meta name="date" content="2016-01-27" />

<title>Excercises manner prediction</title>

<script src="machine_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="machine_files/bootstrap-3.3.1/css/bootstrap.min.css" rel="stylesheet" />
<script src="machine_files/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="machine_files/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="machine_files/bootstrap-3.3.1/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="machine_files/highlight/default.css"
      type="text/css" />
<script src="machine_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Excercises manner prediction</h1>
<h4 class="author"><em>Evgeniy Zabrodskiy</em></h4>
<h4 class="date"><em>27 January 2016</em></h4>
</div>


<div id="synopsis" class="section level2">
<h2>1. Synopsis</h2>
<p>The goal of this project is to find a prediction model that would be able to correctly classify activity type of the individual based on dataset contaning measurements from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.</p>
</div>
<div id="initializing-and-reading-data" class="section level2">
<h2>2. Initializing and reading data</h2>
<pre class="r"><code>library(caret)
library(e1071)
library(randomForest)
library(ggplot2)
library(grid)
library(gridExtra)

motiondata &lt;- read.csv(&quot;pml-training.csv&quot;)
quizdata &lt;- read.csv(&quot;pml-testing.csv&quot;)</code></pre>
</div>
<div id="exploratory-analysis" class="section level2">
<h2>3. Exploratory analysis</h2>
<p>Looking at the variables in the dataset we can see that there are lots of columns with NA values and it makes no sense to use them for prediction. Some other columns in the beginning of the dataset are also not needed and will be removed at the cleaning stage.<br />To give an idea on how prediction model may distinguish between different activity types we can look at the density graphs of different predictors values.</p>
<pre class="r"><code>q1 &lt;- qplot(roll_arm, data = motiondata, geom = &quot;density&quot;, color = classe)
q2 &lt;- qplot(yaw_arm, data = motiondata, geom = &quot;density&quot;, color = classe)
q3 &lt;- qplot(total_accel_arm, data = motiondata, geom = &quot;density&quot;, color = classe)
q4 &lt;- qplot(gyros_arm_x, data = motiondata, geom = &quot;density&quot;, color = classe)
q5 &lt;- qplot(gyros_arm_y, data = motiondata, geom = &quot;density&quot;, color = classe)
q6 &lt;- qplot(gyros_arm_z, data = motiondata, geom = &quot;density&quot;, color = classe)
q7 &lt;- qplot(accel_arm_x, data = motiondata, geom = &quot;density&quot;, color = classe)
q8 &lt;- qplot(accel_arm_y, data = motiondata, geom = &quot;density&quot;, color = classe)
q9 &lt;- qplot(accel_arm_z, data = motiondata, geom = &quot;density&quot;, color = classe)

graphs &lt;- arrangeGrob(q1, q2, q3, q4, q5, q6, q7, q8, q9, ncol = 3)
grid.draw(graphs)</code></pre>
<p><img src="machine_files/figure-html/graphs-1.png" /></p>
</div>
<div id="cleaning-data" class="section level2">
<h2>4. Cleaning data</h2>
<p>Keep columns which may be useful for prediction (measurements from sensors), remove columns with NA values and some other columns which make no sense for prediction, such as measurement number, different timestamps, window flag, window number and user name.</p>
<pre class="r"><code>varnames &lt;- c(&quot;roll_belt&quot;, &quot;pitch_belt&quot;, &quot;yaw_belt&quot;, &quot;total_accel_belt&quot;, 
              &quot;gyros_belt_x&quot;, &quot;gyros_belt_y&quot;, &quot;gyros_belt_z&quot;, 
              &quot;accel_belt_x&quot;, &quot;accel_belt_y&quot;, &quot;accel_belt_z&quot;, &quot;magnet_belt_x&quot;, 
              &quot;magnet_belt_y&quot;, &quot;magnet_belt_z&quot;, &quot;roll_arm&quot;, &quot;pitch_arm&quot;, 
              &quot;yaw_arm&quot;, &quot;total_accel_arm&quot;, &quot;gyros_arm_x&quot;, &quot;gyros_arm_y&quot;, 
              &quot;gyros_arm_z&quot;, &quot;accel_arm_x&quot;, &quot;accel_arm_y&quot;, &quot;accel_arm_z&quot;, 
              &quot;magnet_arm_x&quot;, &quot;magnet_arm_y&quot;, &quot;magnet_arm_z&quot;, &quot;roll_dumbbell&quot;, 
              &quot;pitch_dumbbell&quot;, &quot;yaw_dumbbell&quot;, &quot;total_accel_dumbbell&quot;, 
              &quot;gyros_dumbbell_x&quot;, &quot;gyros_dumbbell_y&quot;, &quot;gyros_dumbbell_z&quot;, 
              &quot;accel_dumbbell_x&quot;, &quot;accel_dumbbell_y&quot;, &quot;accel_dumbbell_z&quot;, 
              &quot;magnet_dumbbell_x&quot;, &quot;magnet_dumbbell_y&quot;, &quot;magnet_dumbbell_z&quot;, 
              &quot;roll_forearm&quot;, &quot;pitch_forearm&quot;, &quot;yaw_forearm&quot;, 
              &quot;total_accel_forearm&quot;, &quot;gyros_forearm_x&quot;, &quot;gyros_forearm_y&quot;, 
              &quot;gyros_forearm_z&quot;, &quot;accel_forearm_x&quot;, &quot;accel_forearm_y&quot;, 
              &quot;accel_forearm_z&quot;, &quot;magnet_forearm_x&quot;, &quot;magnet_forearm_y&quot;, 
              &quot;magnet_forearm_z&quot;)

cleandata &lt;- motiondata[, c(varnames, &quot;classe&quot;)]
cleanquizdata &lt;- quizdata[, c(varnames, &quot;problem_id&quot;)]</code></pre>
<p>Test predictors for variance with the function <code>nearZeroVar</code>. If the variance is close to zero, it will not contribute to prediction and that predictor can be removed from the model.</p>
<pre class="r"><code>nearZeroVar(training, saveMetrics = TRUE)</code></pre>
<p>To keep the report concise, the output is not shown here but the variance of all the predictiors in the cleaned dataset is not close to zero thus all the predictors will be used for further modeling.</p>
</div>
<div id="model-selection" class="section level2">
<h2>5. Model selection</h2>
<p>The strategy for model selection is:<br />1. Divide the dataset to training and testing set for each model that will be tested.<br />2. Try different models. The model with the best accuracy on the test set will be chosen for prediction on the quiz dataset.</p>
<p>During this project several models were tested, such as:<br />* <strong>k-nearest neighbors (knn)</strong> with estimated accuracy ~ 90%. The algorithm was computationally expensive.<br />* <strong>Recursive Partitioning and Regression Trees (rpart)</strong> with very low accuracy ~ 50%.<br />* <strong>Linear discriminant analysis (lda)</strong> (more details below)<br />* <strong>Support Vector Machine (svm) with radial kernel</strong> (more details below)<br />* <strong>Random forrest</strong> (more details below)<br />Only <strong>lda</strong>, <strong>svm</strong> and <strong>rf</strong> models are included in this document.</p>
<div id="data-partitioning" class="section level3">
<h3>5.1. Data partitioning</h3>
<p>A training set and a test set for each model will be generated independently with recommended proportion 60% for a training and 40% for a test set.</p>
<pre class="r"><code>set.seed(1234)
inTrain.lda &lt;- createDataPartition(y = cleandata$classe, p = 0.6, list = FALSE)
training.lda &lt;- cleandata[inTrain.lda,]
testing.lda &lt;- cleandata[-inTrain.lda,]

inTrain.svm &lt;- createDataPartition(y = cleandata$classe, p = 0.6, list = FALSE)
training.svm &lt;- cleandata[inTrain.svm,]
testing.svm &lt;- cleandata[-inTrain.svm,]

inTrain.rf &lt;- createDataPartition(y = cleandata$classe, p = 0.6, list = FALSE)
training.rf &lt;- cleandata[inTrain.rf,]
testing.rf &lt;- cleandata[-inTrain.rf,]</code></pre>
</div>
<div id="linear-discriminant-analysis-model" class="section level3">
<h3>5.2. Linear discriminant analysis model</h3>
<p>This model will be trained with k-fold cross-validation where k = 5.</p>
<pre class="r"><code>set.seed(2345)
trC &lt;- trainControl(method = &quot;cv&quot;, number = 5) # 5-fold cross-validation
fit.lda &lt;- train(classe ~ ., method = &quot;lda&quot;, data = training.lda, trControl = trC)
p.lda &lt;- predict(fit.lda, testing.lda)
cm.lda &lt;- confusionMatrix(p.lda, testing.lda$classe)

fit.lda # print the output of the model</code></pre>
<pre><code>## Linear Discriminant Analysis 
## 
## 11776 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 9421, 9422, 9420, 9421, 9420 
## Resampling results
## 
##   Accuracy   Kappa    Accuracy SD  Kappa SD   
##   0.7027849  0.62376  0.003480186  0.004222837
## 
## </code></pre>
<p>The accuracy of <strong>lda</strong> model is quite low compared to other models tested below.</p>
</div>
<div id="support-vector-machine-model" class="section level3">
<h3>5.3. Support vector machine model</h3>
<pre class="r"><code>set.seed(3456)
fit.svm &lt;- svm(classe ~ ., data = training.svm, cross = 5) # 5-fold cross-validation
p.svm &lt;- predict(fit.svm, testing.svm)
cm.svm &lt;- confusionMatrix(p.svm, testing.svm$classe)

cm.svm$overall[&quot;Accuracy&quot;]</code></pre>
<pre><code>##  Accuracy 
## 0.9374203</code></pre>
<p>Accuracy of <strong>svm</strong> model with default parameters is quite good. Cross-validation does not seem to have had an effect on the accuracy.</p>
</div>
<div id="random-forest-model" class="section level3">
<h3>5.4. Random forest model</h3>
<p>Unfortunately, <code>method = &quot;rf&quot;</code> in <code>train</code> function from <code>caret</code> library loaded CPUs with no result for a long time, that is why randomForest from the original library is used.</p>
<p>Cross-validation is not used because according to <a href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr">source</a>: <em>“In random forests, there is no need for cross-validation or a separate test set to get an unbiased estimate of the test set error. It is estimated internally, during the run”</em></p>
<pre class="r"><code>set.seed(4567)
fit.rf &lt;- randomForest(classe ~ ., data = training.rf, ntree = 100, 
                       importance = TRUE)
fit.rf # print the output of the model</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = classe ~ ., data = training.rf, ntree = 100,      importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 100
## No. of variables tried at each split: 7
## 
##         OOB estimate of  error rate: 0.87%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3340    7    0    1    0 0.002389486
## B   16 2252   11    0    0 0.011847301
## C    0   20 2030    4    0 0.011684518
## D    1    0   31 1894    4 0.018652850
## E    0    1    1    5 2158 0.003233256</code></pre>
<pre class="r"><code>p.rf &lt;- predict(fit.rf, testing.rf)
cm.rf &lt;- confusionMatrix(p.rf, testing.rf$classe)
cm.rf # print the output of confusion matrix of the test set and actual classes</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2229    9    0    0    0
##          B    2 1502    9    0    0
##          C    0    7 1359   10    0
##          D    0    0    0 1275    2
##          E    1    0    0    1 1440
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9948          
##                  95% CI : (0.9929, 0.9962)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9934          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9987   0.9895   0.9934   0.9914   0.9986
## Specificity            0.9984   0.9983   0.9974   0.9997   0.9997
## Pos Pred Value         0.9960   0.9927   0.9876   0.9984   0.9986
## Neg Pred Value         0.9995   0.9975   0.9986   0.9983   0.9997
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2841   0.1914   0.1732   0.1625   0.1835
## Detection Prevalence   0.2852   0.1928   0.1754   0.1628   0.1838
## Balanced Accuracy      0.9985   0.9939   0.9954   0.9956   0.9992</code></pre>
<pre class="r"><code>plot(fit.rf, main = &quot;Random forest model errors&quot;)</code></pre>
<p><img src="machine_files/figure-html/rf-1.png" /></p>
<p>The <strong>random forest</strong> model gave the best prediction accuracy and this model will be used on the quiz set.<br /><strong>Out-of-sample error</strong> can be calculated as <code>1 - Accuracy</code> when the Accuracy is calculated on the <em>testing set</em>.<br />Accuracy = 0.9947744<br />Out-of-sample error = 0.0052256</p>
</div>
</div>
<div id="quiz-predictions" class="section level2">
<h2>6. Quiz predictions</h2>
<pre class="r"><code>quiz &lt;- predict(fit.rf, cleanquizdata)
quiz</code></pre>
<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E</code></pre>
</div>
<div id="references" class="section level2">
<h2>7. References</h2>
<ol style="list-style-type: decimal">
<li>The data for this project came from this source: <a href="http://groupware.les.inf.puc-rio.br/har"><a href="http://groupware.les.inf.puc-rio.br/har" class="uri">http://groupware.les.inf.puc-rio.br/har</a></a></li>
</ol>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
